## CCJS 200 - Statistics for Criminology & Criminal Justice (Spring 2024)

### Course Syllabus

* Course description (from the University catalog): Introduction to descriptive and inferential statistics, graphical techniques, and the computer analysis of criminology and criminal justice data. Basic procedures of hypothesis testing, correlation and regression analysis, and the analysis of continuous and binary dependent variables. Emphasis upon the examination of research problems and issues in criminology and criminal justice.
* Meetings: This course is scheduled to meet on Tuesdays and Thursdays from 11-12:15pm in LeFrak 2205 and I plan to hold office hours on Tuesdays from 1-2:30pm and by appointment (you can email me at rbrame@umd.edu). My office is 2139 LeFrak Hall.
* Graduate Teaching Assistants: Jae Eun (Jane) Lee (jelee18@umd.edu) and Jordan Pierce (jmpierce@umd.edu); they will each be holding their own office hours (Jordan on Monday from 1-2 and Jane on Wednesday from 1-2) and will also be responsible for overseeing discussion sections which will meet on Fridays (please see your registration information to identify your section).  Their office is 2163 LeFrak Hall
* Course-related policies: In all matters, I will follow University guidance as outlined [here](https://www.ugst.umd.edu/courserelatedpolicies.html).
* Accessibility accommodations: As a matter of University policy, I do my best to abide by all recommended accommodations. If you think you might need one or more academic accommodations, please contact the Accessibility and Disability Service Office ([link](https://ads.umd.edu)) for guidance and assistance.
* Email policy: Please refrain from sending messages to us (me, Jane, and Jordan) on ELMS. We ask that you email us directly at our UMD email addresses listed above.
* Required Textbook: Bachman, Paternoster, and Wilson (2022, 5th edition), *Statistics for Criminology and Criminal Justice*. 
* Class Notes: the class notes will be posted on this webpage.
* Letter grades: At the end of the semester, letter grades will be assigned on a 100-point scale (A+ = 97 and higher; A = 93-96; A- = 90-92; B+ = 87-89; B = 83-86; B- = 80-82; C+ = for 77-79; C = 73-76; C- = 70-72; D+ = 67-69; D = 63-66; D- = 60-62; and F = any grade less than 60). All numeric grades (including the final numeric grade in the class at the end of the semester) will be rounded off to the nearest 1 point (for example, a 78.5 would be rounded to a 79 and a 78.4 would be rounded to a 78).
* Numeric grades in this class will be based on 3 in-class exams and 3 out-of-class assignments and will all be graded on a 100-point scale. The final numeric grade calculation at the end of the semester will be: 0.25 x Exam 1 + 0.25 x Exam 2 + 0.25 x Exam 3 + 0.25 x Average Assignment Grade. (Addendum: there will also be a second formula: 0.2 x Exam 1 + 0.2 x Exam 2 + 0.2 x Exam 3 + 0.4 x Average Assignment Grade. At the end of the semester, I will calculate your grade using both approaches and I will assign your grade based on the formula that gives you the higher grade). Any formulas needed for exams will be printed on the exam.
* Key dates: (1) first class day - Thursday 1/25; (2) spring break - 3/19-3/21; (3) last day of class - Thursday 5/9; and (4) scheduled final exam period - Saturday May 11th from 8-10am.
* Attendance expectations: My expectation is that you will attend all of the class and discussion sessions (unless you are sick or have some other good reason not to attend). If you have to miss a class or a discussion section, I encourage you to work with other people in the class to get caught up on your notes and contact me or the TA's if you ever need clarification or assistance. If you have to miss an exam, we will follow the notification and make-up policies specified by the University.
* Statistical software: As noted in the catalog description, there must be a computer component to this course. We will be using R, which is free, easy to get, and works on both Windows and Mac computers.

#### Answers to Important Questions (still part of the syllabus)

* Why do I have to take this course?

The University of Maryland has a General Education curriculum [(link)](https://gened.umd.edu/node/35) which all baccalaureate-level degree recipients must complete. Part of this curriculum is called Fundamental Studies and successful completion of this course (CCJS 200) satisfies the Fundamental Studies Analytic Reasoning (FSAR) requirement. So, when you see FSAR labels associated with this course, that is what those labels refer to. The Analytic Reasoning requirement expresses a belief among the University faculty that analytic reasoning is an essential part of what it means to have received a liberal arts education.

* What does UMD expect us to cover in a class that satisfies the University's analytic reasoning requirement?

According to the Gen-Ed [website](https://gened.umd.edu/students/four-categories/fundamental-studies), "[c]courses in Analytic Reasoning foster a student's ability to use mathematical or formal methods or structured protocols and patterns of reasoning to examine problems or issues by evaluating evidence, examining proofs, analyzing relationships between variables, developing arguments, and drawing conclusions appropriately. Courses in this category advance and build upon the skills that students develop in Fundamental Mathematics."

* Why is this course taught in the CCJS department?

The disciplinary focus of this course reflects a belief by the faculty that analytic reasoning skills can be effectively conveyed through the disciplinary lens of the student's major. The alternative would be to teach a course like this in a math or statistics department and, indeed, this is what is done at some universities. There is no right or wrong way to deliver this kind of course; what we have at Maryland reflects the views of the faculty who work here.

* I don't like math and I'm apprehensive about taking this course. Can you help me feel better about this?

It just so happens that when criminologists do research and evaluation work, they often rely on quantitative data and so it came to pass that we have this class which emphasizes "statistical analysis." Even though you will be performing some calculations and working with some numeric data in this class, the calculations you will be doing are probably best viewed as "arithmetic" (which is a subset of the field of mathematics). This is to emphasize that all of the calculating in this class will be focused on addition, substraction, multiplication, and division -- in other words, skills with which you're pretty familiar. In addition, each chapter of the textbook has practice problems at the end of the chapter with answers to the odd-numbered exercises at the back of the book. I encourage you to build confidence in your ability to solve problems by working on the exercises that coincide with the material we cover in class (please note: we won't address every single topic that is discussed in the book so you should only work on practice problems that are consistent with the class material). As preparation, you are also encouraged to work on the practice arithmetic problems in Appendix A at the back of the textbook. Your discussion sections and office hours are the appropriate venue for getting help with the practice problems. The University also offers the [Math Success Program](https://tltc.umd.edu/students/get-help-class/math-success-program) which may be helpful to you.

* What are the pre-requisites for this class?

You need to have completed CCJS 100 (Intro to Criminal Justice) *or* CCJS 105 (Intro to Criminology); *and* you need to have attained a grade of C- or better in STAT 100 (Elementary Statistics and Probability), MATH 107 (Introduction to Math Modeling and Probability), MATH 120 (Elementary Calculus I), or MATH 135 (Calculus I). Less common, but still acceptable, courses include MATH 111 or MATH 130. If you haven't met these requirements, you should *drop this class now* and return when they've been completed.

* What will I be able to do when this course is over?

These are the course learning outcomes which I have defined as your being able to: (1) explain the meaning, limitations, and calculation of commonly used statistics related to crime and criminal justice; (2) distinguish between descriptive and inferential analysis and how tools in both domains are used to advance knowledge about crime and criminal justice; (3) analyze certain kinds of quantitative criminological evidence, considering both the strengths and weaknesses of methodological approaches often used in our discipline; and (4) perform basic statistical calculations related to criminologically interesting phenomena. 

* What will the assignments and exams be like in this class?

You will have 3 out-of-class assignments in this course; each assignment will consist of substantive and computer-related applications of key concepts taught in class. You will have 1 week to complete each of the out-of-class assignments. Also, each of the assignments will be posted on this webpage and will be submitted on ELMS at or before 11:59pm on the due date (if you submit after 11:59pm on the due date, there will be a 3-point per hour deduction on your assignment grade). All assignments should be submitted in pdf format (3-point deduction for assignments not submitted in pdf format). Exams will involve pencil and paper problems and calculations. For these exams, you will need to have a calculator which can take square roots. You will be able to use your paper notes (no books, phones, or computers) on the exam but we will provide all needed formulas on the exam itself so you will not need to spend any time looking up formulas. On exam days, the full class period will be devoted to the exam. For both out-of-class assignments and exams, you must show us your work in order to receive full credit. In cases where you provide an answer without showing the underlying work (or, when applicable, the relevant computer script and output), you will only receive one-half credit. Similarly, if you get an incorrect answer to a question or problem but you show your work, you will receive partial credit for the work that was done correctly.

* What happens in discussion sections?

Jane and Jordan will be the CCJS 200 teaching assistants this semester and they will oversee the discussion sections each Friday. Both of them are well versed in the concepts and materials we are discussing this semester. During the discussion sections, Jane and Jordan will be answering lecture- and assignment-related questions; they will also go over practice problems at the end of the textbook chapters. They are a valuable resource for you this semester and I encourage you to fully engage with the discussion section each week. 

* How do I get and use R?

R is available at this [website](https://www.r-project.org). You can read about the history of R (it was originally developed at Bell Labs and used to be called S and then S+) at the Wikipedia [page](https://en.wikipedia.org/wiki/R_(programming_language)). To work with R, you will need to use a plain text editor (Notepad on Windows or TextEdit on Macs) or a program like RStudio. I will be going over the basics in class; Jane and Jordan will go over RStudio in the discussion sections. R and RStudio are both available on the OACS ([website](https://oacs.umd.edu/facilities/oacs-computer-labs)) and McKeldin PC's ([website](https://umd.app.box.com/s/6gtvcfbos7x837wlvsf2denyrvghs5w6)).

#### Course Outline

This is an aspirational course outline. I will try to stick to the schedule that is described here. That said, we may need to make some changes as we go along. If that happens, I will notify you as soon as possible.

* Thursday 1/25: Meet & Greet Day + Different kinds of research that rely on quantitative data (chapter 1, part 1)
* Week 1 - 1/30-2/2: Sampling (chapter 1, part 2)
* Week 2 - 2/6-2/9: Descriptive and inferential statistics (chapter 1, part 3)
* Assignment #1 posted on Friday 2/9; due at end of the day on Friday 2/16
* Week 3 - 2/13-2/16: Levels of measurement + dichotomies, counts, rates, and percentages (chapter 2).
* Week 4 - 2/20-2/23: Central tendency (chapter 4).
* Week 5 - 2/27 is catch-up/review day and Exam 1 will be on Thursday 2/29.
* Week 6 - 3/5-3/8: Variation and dispersion (chapter 5)
* Assignment #2 posted on Friday 3/8; due at end of the day on Friday 3/15.
* Week 7 - 3/12-3/15: Probability theory (chapter 6).
* Week 8 -  3/19-3/22: Spring break!
* Week 9 - 3/26-3/29: Point estimation and confidence intervals (chapter 7).
* Week 10 - 4/2 is catch-up/review day and Exam 2 will be on Thursday 4/4.
* Week 11 - 4/9-4/12: Identification intervals (no chapter; I will provide information)
* Assignment #3 posted on Friday 4/12; due at end of the day on Friday 4/19.
* Week 12 - 4/16-4/19: One-sample hypothesis tests (chapter 8).
* Week 13 - 4/23-4/26: Categorical data (chapter 9).
* Week 14 - 4/30-5/3: Two-sample tests (chapter 10).
* Week 15 - 5/7-5/9: Correlation/regression (chapter 12) + final exam review.
* Final exam - Saturday 5/11: 8am-10am ([official university exam schedule](https://registrar.umd.edu/registration/register-classes/final-exams/spring-2024)).

### Lesson 1 - Thursday 1/25/24

* Assigned reading: Chapter 1.
* Slides in pdf format ([link](https://github.com/rwb/ccjs200/blob/main/gfiles/lesson1.pdf)).
* Some links mentioned in today's lesson are listed below.
* Uniform Crime Reports - let's look at [2018](https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018) and [2019](https://ucr.fbi.gov/crime-in-the-u.s/2019/crime-in-the-u.s.-2019/topic-pages/offenses-known-to-law-enforcement).
* National Crime Victimization Survey (previously called the National Crime Survey), most recent [report](https://bjs.ojp.gov/document/cv22.pdf). 
* 2022 Juvenile Court Data ([report](https://ojjdp.ojp.gov/publications/2022-national-report.pdf)).
* Washington Post police shootings [database](https://www.washingtonpost.com/graphics/investigations/police-shootings-database/).

### Lesson 2 - Tuesday 1/30/24

* Assigned Reading: Chapter 1 (continued).
* Update on course grading: I've decided that at the end of the semester, I will calculate your grades two different ways. The first way will assign 25% weight to each of your exams and 25% weight to the average of your assignment grades. That is what is presented in the syllabus. Second, however, I will calculate your grade assigning 20% weight to each of your exams and 40% weight to the average of your assignment grades. I will assign your final letter grade based on the higher grade out of these 2 calculations.
* Slides in pdf format ([link](https://github.com/rwb/ccjs200/blob/main/gfiles/lesson2.pdf)).
* Washington Post [article](https://www.washingtonpost.com/opinions/2023/11/08/violent-crime-data-2022-mystifying/) mentioned in class.
* Uniform Crime Reports handling of 9/11/2001 terror attack ([link](https://ucr.fbi.gov/crime-in-the-u.s/2001/toc01.pdf)).

### Lesson 3 - Thursday 2/1/24

* Assigned Reading: Chapter 1 (continued).
* Slides in pdf format ([link](https://github.com/rwb/ccjs200/blob/main/gfiles/lesson3.pdf)).
* R [website](https://www.r-project.org).
* RStudio [website](https://posit.co/download/rstudio-desktop/).
* OACS Computer Labs, bottom floor of LeFrak ([website](https://oacs.umd.edu/facilities/oacs-computer-labs)). 

### Lesson 4 - Tuesday 2/6/24

* Assigned Reading: Chapter 1 (continued).
* Note: we will finish chapter 1 this week and we will post the first assignment on Friday 2/9/24 (due on Friday 2/16/24).
* Slides in pdf format ([link](https://github.com/rwb/ccjs200/blob/main/gfiles/lesson4.pdf)).

### Lesson 5 - Thursday 2/8/24

* Assigned Reading: Chapter 1 (continued).
* Slides in pdf format ([link](https://github.com/rwb/ccjs200/blob/main/gfiles/lesson5.pdf)).
* Please note: to avoid copy/paste problems, all R code and output we have covered so far is included below.
* In the future, all R code will be posted directly on Github.

### R code for our examples so far

* Basic Calculations in R

```R
x=2
y=3
x+y
x-y
x*y
x/y
x^y
factorial(x*y)
sqrt(y^x)
```

Here is the output:

```Rout
> x=2
> y=3
> x+y
[1] 5
> x-y
[1] -1
> x*y
[1] 6
> x/y
[1] 0.6666667
> x^y
[1] 8
> factorial(x*y)
[1] 720
> sqrt(y^x)
[1] 3
>
```

* Calculating your grade example

```R
exam1=77
exam2=81
exam3=80
assignment1=93
assignment2=87
assignment3=88
average.assignment=mean(assignment1,assignment2,assignment3)
average.assignment
formula1=0.25*exam1+0.25*exam2+0.25*exam3+0.25*average.assignment
formula1
formula2=0.2*exam1+0.2*exam2+0.2*exam3+0.4*average.assignment
formula2
```

Here is the output:

```Rout
> exam1=77
> exam2=81
> exam3=80
> assignment1=93
> assignment2=87
> assignment3=88
> average.assignment=mean(assignment1,assignment2,assignment3)
> average.assignment
[1] 93
> formula1=0.25*exam1+0.25*exam2+0.25*exam3+0.25*average.assignment
> formula1
[1] 82.75
> formula2=0.2*exam1+0.2*exam2+0.2*exam3+0.4*average.assignment
> formula2
[1] 84.8
>
```

* Household Burglaries in Charlotte and Wilmington Example

```R
nburg.clt=7305
nburg.wil=1109
nburg.clt/nburg.wil
pop.clt=779541
pop.wil=106476
burgrate.clt=(nburg.clt/pop.clt)*100000
burgrate.clt
burgrate.wil=(nburg.wil/pop.wil)*100000
burgrate.wil
burgrate.clt/burgrate.wil
```

And, here are the results:

```Rout
> nburg.clt=7305
> nburg.wil=1109
> nburg.clt/nburg.wil
[1] 6.587015
> pop.clt=779541
> pop.wil=106476
> burgrate.clt=(nburg.clt/pop.clt)*100000
> burgrate.clt
[1] 937.0899
> burgrate.wil=(nburg.wil/pop.wil)*100000
> burgrate.wil
[1] 1041.549
> burgrate.clt/burgrate.wil
[1] 0.8997077
>
```

* UCR Murder Rates by Year (1994-2019) Example

```R
year=seq(from=1994,to=2019,by=1)

murders=c(23326,21606,19645,18208,16974,15522,
15586,16037,16229,16528,16137,16692,17034,
16929,16272,15241,14748,14612,14827,14196,
14249,15696,17250,17284,16214,16425)

pop=c(259177778,263487805,265472973,267764706,
269428571,272315789,283381818,286375000,
289803571,289964912,293400000,298071429,
293689655,297000000,301333333,304820000,
307250000,310893617,315468085,315466667,
323840909,320326531,325471698,326113208,
324280000,328500000)

mrate=(murders/pop)*100000

plot(x=year,y=mrate,type="l",ylim=c(0,10),
  main="UCR Murder Rates by Year (1994-2019)",
  xlab="Year (1994-2019)",
  ylab="# of Murders per 100k Population")
points(x=year,y=mrate,pch=19)
```

and here is our output:

<p align="center">
<img src="/gfiles/f1.png" width="700px">
</p>

* Age of People Released from NC Prisons in 1978 Example

```R
# read the dataset - NC Department of Corrections FY1978 Releases

age=c(rep(16,19),rep(17,161),rep(18,492),rep(19,480),rep(20,624),
  rep(21,599),rep(22,580),rep(23,468),rep(24,537),rep(25,443),rep(26,432),
  rep(27,338),rep(28,415),rep(29,292),rep(30,324),rep(31,254),rep(32,234),
  rep(33,179),rep(34,187),rep(35,167),rep(36,177),rep(37,132),rep(38,152),
  rep(39,117),rep(40,119),rep(41,93),rep(42,113),rep(43,102),rep(44,85),
  rep(45,75),rep(46,90),rep(47,72),rep(48,86),rep(49,62),rep(50,78),
  rep(51,61),rep(52,57),rep(53,50),rep(54,44),rep(55,49),rep(56,55),
  rep(57,34),rep(58,34),rep(59,25),rep(60,21),rep(61,18),rep(62,19),
  rep(63,11),rep(64,16),rep(65,7),rep(66,5),rep(67,13),rep(68,5),rep(69,3),
  rep(70,1),rep(71,3),rep(72,5),rep(73,3),rep(74,4),rep(75,2),rep(77,2),rep(78,2))
n=length(age)
n

# part 1: create a chart

barplot(table(age),
  xlab="Age (in years) at Time of Release",
  ylab="Number of People",
 main="Age at Release from Prison (1978 NCDOC)") 

# part 2: average age at release for the population

mean(age)
```

* Here is the output:

```Rout
> # read the dataset - NC Department of Corrections FY1978 Releases
> 
> age=c(rep(16,19),rep(17,161),rep(18,492),rep(19,480),rep(20,624),
+   rep(21,599),rep(22,580),rep(23,468),rep(24,537),rep(25,443),rep(26,432),
+   rep(27,338),rep(28,415),rep(29,292),rep(30,324),rep(31,254),rep(32,234),
+   rep(33,179),rep(34,187),rep(35,167),rep(36,177),rep(37,132),rep(38,152),
+   rep(39,117),rep(40,119),rep(41,93),rep(42,113),rep(43,102),rep(44,85),
+   rep(45,75),rep(46,90),rep(47,72),rep(48,86),rep(49,62),rep(50,78),
+   rep(51,61),rep(52,57),rep(53,50),rep(54,44),rep(55,49),rep(56,55),
+   rep(57,34),rep(58,34),rep(59,25),rep(60,21),rep(61,18),rep(62,19),
+   rep(63,11),rep(64,16),rep(65,7),rep(66,5),rep(67,13),rep(68,5),rep(69,3),
+   rep(70,1),rep(71,3),rep(72,5),rep(73,3),rep(74,4),rep(75,2),rep(77,2),rep(78,2))
> n=length(age)
> n
[1] 9327
> 
> # part 1: create a chart
> 
> barplot(table(age),
+   xlab="Age (in years) at Time of Release",
+   ylab="Number of People",
+  main="Age at Release from Prison (1978 NCDOC)") 
> 
> # part 2: average age at release for the population
> 
> mean(age)
[1] 29.32787
>
```

and here is the chart for the population:

<p align="center">
<img src="/gfiles/f2.png" width="700px">
</p>

* Now, let's draw a simple random sample from the population, calculate the sample average, and draw a sample barplot.

```R
# part 3: study a simple random sample

s=sample(1:n,size=100,replace=T)
sample.age=age[s]
mean(sample.age)

# part 4: create a chart showing the ages in the sample

barplot(table(sample.age),
  xlab="Age (in years) at Time of Release",
  ylab="Number of People",
 main="Age at Release for Random Sample")
```

* Here is the output for the random sample:

```Rout
> # part 3: study a simple random sample
> 
> s=sample(1:n,size=100,replace=T)
> sample.age=age[s]
> mean(sample.age)
[1] 31.18
> 
> # part 4: create a chart showing the ages in the sample
> 
> barplot(table(sample.age),
+   xlab="Age (in years) at Time of Release",
+   ylab="Number of People",
+  main="Age at Release for Random Sample")
>
```

<p align="center">
<img src="/gfiles/f3.png" width="700px">
</p>

### Assignment #1 - Due 11:59pm Friday 2/16/24

* Instructions: Please complete each of the 3 parts listed below. You are allowed to discuss your work with other students and the TA's but the work you submit should be your own work. If you have a question you want to submit in writing, we ask that you post it to the discussion board rather than email. If you do not want to be identified as a questioner by the rest of the class, you may send your question to one of us and we will respond (during business hours). Please note that all questions and answers that we judge to be of interest to the entire class will also be posted on the discussion board. This assignment will be due in pdf format on ELMS by 11:59pm on Friday February 16, 2024.

* Part 1: In 2011, Greensboro police recorded 3,279 household burglaries while Durham police recorded almost the same number -- 3,283. According to the state population database, Greensboro had 263,279 residents in 2011 while Durham had 222,978. Based on this information calculate the number of household burglaries per 100,000 population in each city and identify the city with the higher household burglary rate. Write a sentence where you describe what you learned from this comparison.

* Part 2: The table gives the total number of homicides in the U.S. for each year from 1994-2019 based on death certificate data from the National Vital Statistics System (NVSS). Using these data construct a figure showing the yearly homicide rates per 100,000 population (similar to the in-class example where we calculated homicide rates using the UCR data). Comment on which series tends to have higher levels -- the one based on UCR data or this one based on the CDC death certificate data.

<p align="center">
<img src="/gfiles/homicide-table.png" width="700px">
</p>

* Part 3: In practice exercise 3, we looked at the age distribution of North Carolina prison releasees in 1978. For this task, you will examine a similar age distribution for the 9,549 people who were released from prison in 1980. The R code for the ages are printed below:

```R
age=c(rep(15,1),rep(16,20),rep(17,224),rep(18,504),rep(19,472),rep(20,626),
  rep(21,517),rep(22,601),rep(23,516),rep(24,565),rep(25,407),rep(26,495),
  rep(27,302),rep(28,397),rep(29,291),rep(30,298),rep(31,261),rep(32,330),
  rep(33,224),rep(34,231),rep(35,163),rep(36,194),rep(37,157),rep(38,149),
  rep(39,125),rep(40,129),rep(41,116),rep(42,100),rep(43,88),rep(44,105),
  rep(45,88),rep(46,80),rep(47,72),rep(48,60),rep(49,68),rep(50,67),
  rep(51,64),rep(52,50),rep(53,47),rep(54,51),rep(55,47),rep(56,42),
  rep(57,28),rep(58,39),rep(59,12),rep(60,29),rep(61,12),rep(62,13),
  rep(63,8),rep(64,19),rep(65,12),rep(66,9),rep(67,2),rep(68,5),rep(69,3),
  rep(70,6),rep(71,1),rep(73,2),rep(74,2),rep(75,1),rep(77,1),rep(79,1))
```

With these ages, you should construct a barplot showing the age distribution for the population of people released from prison in 1980. Next, you should calculate the average age at the time of release for the 1980 cohort. Then, you are asked to draw a simple random sample of 300 people from this population. Create a barplot showing the age distribution for your random sample of people released from prison. Calculate the average age at the time of release for the sample. Compare your population average from 1980 to the population average in 1978. Which one is greater? Now, draw a simple random sample of 300 people from your 1978 population. Compare your sample average from 1978 to your sample average from 1980. Finally, compare the conclusions you draw for the 2 populations to the conclusions you draw from your 2 random samples. *Note*: when I say "compare" I mean show the numeric answers and write a sentence interpreting your results.

### Lesson 6 - Tuesday 2/13/24

1. Assigned Reading - Chapter 2 of textbook.
2. Definition of a variable: a quantity that can take on different values.
3. Definition of a constant: a quantity that can take on only a single value.
4. In descriptive research, we seek to describe the *location* and the *distribution* of scientifically interesting variables.
5. In causal research, we seek to *explain* the variation that is observed in a scientifically interesting variable.
6. In evaluation research, we might do both.
7. A *sample space* is a list or set of all possible outcomes (values that a variable could have).
8. The outcomes in a sample space must be mutually exclusive and exhaustive.
9. A *frequency distribution* tells us the number of times that a variable takes on each value in the sample space (slightly different from the book's definition).
10. Variables can be categorized by *level of measurement*.
11. The most basic distinction is between *qualitative* (categorical) and *quantitative* (continuous) variables.
12. Within the category of qualitative variables, there are *nominal* (unordered categories) and *ordinal* (small number of ordered categories; the distance between any of the categories is not well defined).
13. Within the category of quantitative variables, there are *interval* (many ordered categories but no true zero) and *ratio* (continuous with a true zero) variables.
14. Examples of qualitative variables: (1) *nominal*: type of robbery (commercial robbery, personal robbery, purse snatching); and (2) *ordinal*: level of injury in a victimization (no injury, injured but not hospitalized, injured and hospitalized but survived, and fatal injury).
15. Examples of quantitative variables: (1) interval: an offense gravity score for criminal sentencing; and (2) ratio: amount of money stolen from the victim in a robbery.
16. In criminology, we are typically concerned with *random variables* where we accept the idea that each outcome in the sample space (for qualitative variables) or interval of the sample space (for quantitative variables) occurs with a probability, *p*. So, if there are two outcomes in the sample space it makes sense to think about outcome 1 occurring with probability, *p<sub>1</sub>*, and outcome 2 occurring with probability, *p<sub>2</sub>*.
17. In this class, we think about *p* in terms of relative frequencies (note: a relative frequency is the number of times an event occurs divided by the total number of times it could have occurred).
19. Example: in a sample of 1,000 prison releasees, we find that 675 people failed (recidivism) while the remaining 325 people did not fail. In this example, *failure* is a random variable where the sample space has two outcomes, "failed" or "did not fail". Thus, *p*(failed) = 675/1000 = 0.675 and *p*(did not fail) = 325/1000 = 0.325. 
20. Note that *p* must always be a number in the interval [0,1]. The bracket [] notation means that the numbers 0 and 1 are included in the interval so that 0 ≤ *p* ≤ 1.
21. When *p* = 0, we say the outcome cannot occur; symmetrically, when *p* = 1, we say that the outcome must occur.
22. The sum of the probabilities of the outcomes in the sample space is 1.0 (for quantitative variables, the sum is an integral).
23. Sometimes, we consider the probabilities of each of the outcomes in a sample space together; the set of probabilities corresponding to the outcomes in a sample space is called a *probability distribution*.
24. Example: we interview a sample of people exiting prison to measure their risk of recidivism. Based on the answers, we divide the respondents (people who participate in a survey) into 3 groups: low, medium, and high risk.

| Outcomes    | N = |
| :---------- | --: |
| Low Risk   | 773        |
| Medium Risk  | 242        |
| High Risk | 108        |
| Total | 1123 |

Questions about this example: (1) what is the level of measurement?: (2) what are the outcomes in the sample space?; (3) what are the relative frequencies for each of the outcomes?; (4) what is the probability that someone drawn at random from this sample is high risk?;

### Lesson 7 - Thursday 2/15/24

1. Reminder: first assignments are due on ELMS by 11:59pm on Friday 2/16/24; after that point, late submission deductions begin. You must submit your assignment in a pdf file.
2. Assigned reading, Chapter 2; you can also go ahead and begin looking at chapter 4.
3. Recall from our last class that we presented a taxonomy of different kinds of variables corresponding to their levels of measurement. Here is a summary:

<p align="center">
<img src="/gfiles/vartypes.png" width="600px">
</p>

4. Dichotomous/binary variables: 2-category variables that usually measure either the presence or absence of an attribute, experience, or intervention. This means the sample space is usually written down in terms of the presence or absence of a condition. Examples: (1) whether someone gets arrested; (2) whether someone has been a crime victim; (3) whether a study participant has been assigned to a treatment or control group; (4) whether a state has the death penalty; and (5) whether a U.S. county experienced any homicides in a given year. With dichotomous or binary variables, we are often interested in the fraction or proportion of cases that/who are in each category of the sample space.
5. Event count variables: these are variables that measure the number of times that something happens, so the sample space is comprised of positive integers (whole numbers). Event counts are qualitative variables in the sense that the sample space is only comprised of integers (fractional values of counts for a specific unit don't make sense). But it does make sense to think about averages of counts. Statements like 2x is twice the number of events as 1x (where x is a counted variable value) are reasonable because counts can have a true zero. Event counts are often converted into rates, where we divide the count by some amount of time or by some number of people (to get the number of events in a particular period of time (say, 1 year) or the number of events per number of people in the population (say, 100,000 people)). 
6. Criminologists have to be careful in their analysis of binary and count variables because they present special analysis issues.
7. In scientific work, we distinguish between independent variables (potential causes) and dependent or outcome variables. Example: Suppose we hypothesize that poor school performance is a cause of juvenile delinquency and we collect data to test this hypothesis. In our study, we would characterize "school performance" as our independent variable and "juvenile delinquency" as our outcome or dependent variable.
8. It is also essential that we clearly define the *unit of analysis* in any empirical study. The number of cases in the study can help us think about this.
   - Example 1: from your assignment that is due tomorrow, the unit of analysis in the NC age at time of release from prison study, the unit of analysis is each individual person leaving a NC prison in the year 1980 (N = 9,549).
   - Example 2: also, from your assignment this week, the unit of analysis in the CDC homicide study is the year (1994-2019; N = 26).
   - Whenever you encounter a study you should try to clearly identify the unit of analysis (a description of the particular cases being studied).
9. Two of the issues of particular concern are properly documenting: (1) the amount of change that occurs from one time to the next; and (2) the variation in how often something happens between different groups.
10. Example 1: In 2018, the city of Pittsburgh reported that there were 57 murders known to the police ([link](https://ucr.fbi.gov/crime-in-the-u.s/2018/crime-in-the-u.s.-2018/tables/table-8/table-8-state-cuts/pennsylvania.xls)). By comparison, the city of Philadelphia reported 351 murders. These are both counts. Yet it is problematic to compare them directly in terms of a discussion about which city experiences a higher incidence of murders. The problem is the 2 cities have vastly different population sizes: Philadelphia's population in 2018 was estimated to be 1,586,916 while Pittsburgh's population was estimated to be 302,544. Surely, this should be taken into consideration. Here is how we could do it:

- Pittsburgh: # of murders per 100,000 population = (57/302544)*100000 = 18.8
- Philadelphia: # of murders per 100,000 population = (351/1586916)*100000 = 22.1

Based on this comparison, we can say that Philadelphia's murder rate is higher than Pittsburgh's but it is a dramatically different story than a comparison of 351 to 57.

11. Example 2: Each year, the National Crime Victimization Survey (NCVS) publishes a national personal robbery victimization rate per 1,000 persons covering the entire nation. For the year [2018](https://bjs.ojp.gov/content/pub/pdf/cv21.pdf) (go to Table 1 on page 2 to see the data), the estimated number of robberies was 573,100 and the rate was estimated to be 2.1 robberies per 1,000 persons. For 2019, the estimated number of robberies was 534,420 while the rate was estimated to be 1.9 robberies per 1,000 population. Using both the count and the rate, we would infer that robberies dropped. However, we can quantify both drops by using the *percent change* statistic. To get the percent change, we have to decide which year will be the base year and which year will be the comparison year. When we are comparing years, we usually say that the first year is the base year and the second year is the comparison year. Here is our worked example:

- Base year estimated number of robberies - 2018: 573100
- Comparison year estimate number of robberies - 2019: 534420
- Percent change statistic: ((534420-573100)/573100)*100 = -6.7%

- Base year estimated number of robberies per 1000 persons - 2018: 2.1
- Comparison year estimated number of robberies per 1000 persons - 2019: 1.9
- Percent change statistic: ((1.9-2.1)/2.1)*100 = -9.5%

- Formula: ((comparison year - base year)/base year)*100

Comparing the raw number of estimated robberies from one year to the next is less meaningful than comparing the rates because the nation's estimated population size did not stay the same from one year to the next.

12. Example 3: For several decades, the Bureau of Justice Statistics (BJS) has carefully studies recidivism patterns for various groups of state prison releasees (you can see the collection [here](https://bjs.ojp.gov/data-collection/recidivism-state-prisoners#1-0)). Some relatively recent data appear in this [document](https://bjs.ojp.gov/BJS_PUB/rpr24s0810yfup0818/Web%20content/508%20compliant%20PDFs). Suppose we want to measure the fraction of people who were released from prison who are in each of 3 age groups. Here is our data:

| Age at Release from Prison    | N = | # Rearrested |
| :---------- | --: | --:|
| Age ≤ 24    | 62,700 | 47,000 |
| Age 25-39   | 206,000  | 141,500 |
| Age ≥ 40    | 140,600 | 82,400 |
| Total        | 409,300 | 270,900 |

- Based on this information, we could calculate the fraction or proportion of people who were in the youngest age group using the proportion formula on page 36:
- Proportion formula = Number of people in subset of sample / Total number of people in sample
- Calculation: 62700/409300 = 0.153
- Proportions can also be called *relative frequencies* (see top of page 37).
- Now, we often want to convert proportions into percentages which we can do by using the proportion to percent conversion formula on page 37.
- Proportion to percent conversion formula: Estimated proportion x 100
- Application: 0.153*100 = 15.3%
- Convince yourself that if you calculate the proportions and percentages for the other 2 age groups that all 3 of them will add up to 1 (proportions) and 100 (percents).
- *Note*: once you have calculated the proportion of people who are in each age group, you have the *relative frequency distribution*.

13. Example 3 (Continued): Suppose you are asked to write a report to a legislative committee studying recidivism and you are responsible for describing how the "recidivism rate" varies between age groups. How would you proceed? What would your analysis show?
- Our first step would be to define the term *recidivism rate*. When people use this term, they are usually referring to the proportion or percent of people who get rearrested, reconvicted, or reimprisoned within some well-defined time period. The definition we are using is *rearrest* and the time period on which these data are based is 3 years. This is an example of an operational definition. Our next step is to calculate the proportion of people who get rearrested within 3 years of the time of prison release.
- Formula for recidivism rate (proportion rearrested) for age group *g*: # of people in subgroup *g* who got rearrested / total # of people in subgroup *g*
- For the youngest age group: 47000/62700 = 0.750
- Expressed in percent terms: 0.750 x 100 = 75.0%
- Next, you can calculate the proporton or percent rearrested for the other 2 age groups. Which group has the highest recidivism rate? (*Hint*: it is not the group with the largest number of people getting rearrested).

14. Sample spaces (review): What is the sample space for the age at release variable?
15. Sample spaces (review): What is the sample space for the rearrest/recidivism variable?
16. Alphanumeric data (page 27): when we have qualitative/categorical or dichotomous variables, we can symbolize the elements in the sample space with either numbers or letters. Here is a computer example to illustrate:

```R
# enter the data
age <- c(rep("age <= 24",62700), rep("age 25-39",206000),rep("age >= 40",140600))

# frequency distribution for age groups
table(age)

# total number of people in the study

length(age)

# proportion of people in each age group

table(age)/length(age)

# percent of people in each age group

(table(age)/length(age))*100
```
* Here is the output:

```Rout
> # enter the data
> age <- c(rep("age <= 24",62700), rep("age 25-39",206000),rep("age >= 40",140600))
> 
> # frequency distribution for age groups
> table(age)
age
age <= 24 age >= 40 age 25-39 
    62700    140600    206000 
> 
> # total number of people in the study
> 
> length(age)
[1] 409300
> 
> # proportion of people in each age group
> 
> table(age)/length(age)
age
age <= 24 age >= 40 age 25-39 
0.1531884 0.3435133 0.5032983 
> 
> # percent of people in each age group
> 
> (table(age)/length(age))*100
age
age <= 24 age >= 40 age 25-39 
 15.31884  34.35133  50.32983 
>
```
* Now, let's do the same exercise with the age groups coded numerically:

```R
# enter the data
age <- c(rep(1,62700), rep(2,206000),rep(3,140600))

# frequency distribution for age groups
table(age)

# total number of people in the study

length(age)

# proportion of people in each age group

table(age)/length(age)

# percent of people in each age group

(table(age)/length(age))*100
```

* Here is the output:

```Rout
> # enter the data
> age <- c(rep(1,62700), rep(2,206000),rep(3,140600))
> 
> # frequency distribution for age groups
> table(age)
age
     1      2      3 
 62700 206000 140600 
> 
> # total number of people in the study
> 
> length(age)
[1] 409300
> 
> # proportion of people in each age group
> 
> table(age)/length(age)
age
        1         2         3 
0.1531884 0.5032983 0.3435133 
> 
> # percent of people in each age group
> 
> (table(age)/length(age))*100
age
       1        2        3 
15.31884 50.32983 34.35133 
>
```

* Notice what changed and what stayed the same.

17. Dichotomous/binary variables can also be coded alphanumerically or just numerically. The advantage of coding them alphanumerically is that it is easy to see what the categories mean. The advantage of coding them with numbers is that we can easily do calculations using the codes. Here is an example using the recidivism data from the table in #11 above. For this example, please note that the number of people who got rearrested was 270,900; this means the number of people who did not get rearrested was 409300-270900 = 138400. First, we code recidivism alphanumerically.

```R
# enter the data
r <- c(rep("no rearrest",138400),rep("rearrest",270900))

# calculate the frequency table

table(r)

# count the number of people in the study

length(r)

# calculate the relative frequency table (i.e., the proportion or fraction of people in each group)

table(r)/length(r)

# convert to percents

(table(r)/length(r))*100
```
Here is the output:

```Rout
> # enter the data
> r <- c(rep("no rearrest",138400),rep("rearrest",270900))
> 
> # calculate the frequency table
> 
> table(r)
r
no rearrest    rearrest 
     138400      270900 
> 
> # count the number of people in the study
> 
> length(r)
[1] 409300
> 
> # calculate the relative frequency table (i.e., the proportion or fraction of people in each group)
> 
> table(r)/length(r)
r
no rearrest    rearrest 
  0.3381383   0.6618617 
> 
> # convert to percents
> 
> (table(r)/length(r))*100
r
no rearrest    rearrest 
   33.81383    66.18617 
>
```

* Next, let's code recidivism numerically:

```R
# enter the data
r <- c(rep(0,138400),rep(1,270900))

# calculate the frequency table

table(r)

# count the number of people in the study

length(r)

# calculate the relative frequency table (i.e., the proportion or fraction of people in each group)

table(r)/length(r)

# convert to percents

(table(r)/length(r))*100

# calculate the recidivism rate by taking the average of the 0's and 1's

mean(r)

# convert to a percent

mean(r)*100
```

* Here is the output:

```Rout
> # enter the data
> r <- c(rep(0,138400),rep(1,270900))
> 
> # calculate the frequency table
> 
> table(r)
r
     0      1 
138400 270900 
> 
> # count the number of people in the study
> 
> length(r)
[1] 409300
> 
> # calculate the relative frequency table (i.e., the proportion or fraction of people in each group)
> 
> table(r)/length(r)
r
        0         1 
0.3381383 0.6618617 
> 
> # convert to percents
> 
> (table(r)/length(r))*100
r
       0        1 
33.81383 66.18617 
> 
> # calculate the recidivism rate by taking the average of the 0's and 1's
> 
> mean(r)
[1] 0.6618617
> 
> # convert to a percent
> 
> mean(r)*100
[1] 66.18617
>
```

* Again, please note what stayed the same and what changed.

18. A short example to clarify the use of 0/1 codes for dichotomous/binary variables:
* Say we are in a state that has the death penalty and we want to look at the last 6 executions.
* In each of the 6 cases, we code the case 1 if the person had been on death row for more than 10 years and 0 if the person had been on death row for less than 10 years.
* Based on this rule, 4 of our 6 cases had been on death row for more than 10 years so they receive a code of 1; the other 2 had been on death row for less than 10 years so they receive a code of 0.
* If we add up our 0's and 1's, we get the following: 1+1+1+1+0+0 = 4.
* The 4 represents the sum of the scores.
* Since there are 6 cases, the number of scores is 6.
* The average or the mean is the sum of the scores divided by the number of scores which -- in this case -- means we have 4/6 = 2/3 or about 0.667.
* So, the mean of the 0's and 1's corresponds to the proportion or fraction of cases that have a code of 1 (i.e., the fraction of people who spent more than 10 years on death row before execution).
